# [TIL] robots.txt

---

## robots.txt

우리가 방문하는 웹사이트들은 검색 엔진 로봇들의 접근을 허용해주거나 어느 부분까지 접근해야 하는지를 알려주면서 사이트맵이 어디에 어떻게 있는지 알려주는 역할을 한다. 사람들이 자주 이용하는 검색 엔진의 로봇들이 각 사이트들을 돌면서 필요한 정보를 크롤링해서 결과로 노출시키게 된다. 그렇게 우리는 검색엔진 최적화를 조절할 수 있게 된다.

해당 사이트의 검색 엔진 허용 상태를 확인하려면 각 사이트 주소 뒤에 /robots.txt 라고 적으면 된다.

이 파일은 텍스트파일로 작성되서 루트 디렉토리에 위치하게 되면 검색 로봇들이 알아서 찾아간다. 만약 위치가 변경되면 검색되지 않으니 위치는 신경쓰도록 한다.

중복되는 결과를 줄임으로써 효과적으로 노출시키고 최적화시킬 수 있음을 기억한다.